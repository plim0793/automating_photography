{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "BACKEND:  tensorflow\n"
     ]
    }
   ],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions, preprocess_input\n",
    "from keras.applications import InceptionV3, ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import re\n",
    "import skvideo.io\n",
    "import datetime\n",
    "import shutil\n",
    "import uuid\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import imageio\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "% pylab inline\n",
    "% matplotlib inline\n",
    "\n",
    "print(\"BACKEND: \", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def augment(image_path, new_path, repeat=5):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - repeat is an integer value stating the number of augmented images per clean image.\n",
    "        - new_path is the relative directory to save the augmented images to.\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "    img_paths = []\n",
    "    \n",
    "    for i in range(repeat):\n",
    "        new_dim = int(img_arr.shape[1] * np.random.uniform(low=0.1, high=0.3))\n",
    "        new_img_arr = resize_img(img_arr, new_dim)\n",
    "\n",
    "        deg = np.random.randint(15, 345)\n",
    "        scale = np.random.uniform(low=1, high=4)\n",
    "        new_img_arr = rotate_img(new_img_arr, deg, scale)\n",
    "        \n",
    "        lower_height = np.random.randint(15, new_img_arr.shape[0])\n",
    "        lower_width = np.random.randint(15, new_img_arr.shape[1])\n",
    "        upper_height = np.random.randint(lower_height, 10000)\n",
    "        upper_width = np.random.randint(lower_width, 10000)\n",
    "\n",
    "        new_img_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "        \n",
    "        if not os.path.isdir(new_path):\n",
    "            os.mkdir(new_path)\n",
    "            print(\"Created {} directory\".format(new_path))\n",
    "            \n",
    "        new_img_path = os.path.join(new_path, str(uuid.uuid4()) + '.jpg')\n",
    "\n",
    "        new_img = cv2.imwrite(new_img_path, new_img_arr)\n",
    "        img_paths.append(new_img_path)\n",
    "        if not new_img:\n",
    "            print(\"Check image path: \", new_img_path)\n",
    "            img_paths.append('')\n",
    "    \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(paths, augment=False, aug_file_path=None):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Generates the list of image file paths.\n",
    "    INPUT:\n",
    "        - paths is an iterable object with valid directories.\n",
    "        - If augment is True, then the images in the paths are augmented.\n",
    "            - aug_file_path must also be specified.\n",
    "    OUTPUT:\n",
    "        - If augment is True, then clean_files is a list of clean image file paths \n",
    "          and aug_files is a list of augmented file paths.\n",
    "        - If augment is False, then only one list of file paths are given.\n",
    "    '''\n",
    "    clean_files = []\n",
    "    for path in paths:\n",
    "        if os.path.isdir(path):\n",
    "            clean_files += [path + f for f in listdir(path) if isfile(join(path, f))]\n",
    "        else:\n",
    "            print(\"{} is invalid.\".format(path))\n",
    "            \n",
    "    if augment:\n",
    "        if aug_file_path:\n",
    "            aug_files = []\n",
    "            for item in clean_files:\n",
    "                aug_img = augment(item, repeat=5, new_path=aug_file_path)\n",
    "                \n",
    "            aug_files = [aug_file_path + f for f in listdir(aug_file_path) if isfile(join(aug_file_path, f))]\n",
    "        else:\n",
    "            print(\"Enter in a directory to save augmented images.\")\n",
    "            return clean_files\n",
    "\n",
    "        return clean_files, aug_files\n",
    "    \n",
    "    return clean_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_files(file_paths, perc_list, dir_list):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Moves files to specific directories.\n",
    "    INPUT:\n",
    "        - file_paths is an iterable object with valid file paths.\n",
    "        - perc_list is an iterable object with floats that sum to 1.\n",
    "        - dir_list\n",
    "    OUTPUT:\n",
    "        - If augment is True, then clean_files is a list of clean image file paths \n",
    "          and aug_files is a list of augmented file paths.\n",
    "        - If augment is False, then only one list of file paths are given.\n",
    "    '''\n",
    "    if len(perc_list) > len(dir_list):\n",
    "        print(\"Warning: more percentages ({}) than available directories ({})\".format(len(perc_list, len(dir_list))))\n",
    "    \n",
    "    if len(perc_list) < len(dir_list):\n",
    "        print(\"Error: Too few percentages.\")\n",
    "        return False\n",
    "    \n",
    "    for i, d in enumerate(dir_list):\n",
    "        if not os.path.isdir(d):\n",
    "            os.mkdir(d)\n",
    "        \n",
    "        num_files = int(len(file_paths) * perc_list[i]) - 1\n",
    "        count = 0\n",
    "        cycle_count = 0\n",
    "        for f in file_paths:\n",
    "            if os.path.isfile(f):\n",
    "                shutil.move(f, dest)\n",
    "                count += 1\n",
    "                \n",
    "            file_paths.pop(0)\n",
    "            if count == num_files:\n",
    "                break\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### DONT NEED SINCE USING DATA GENERATOR #####\n",
    "# def get_clean_aug_arrays(tot_count, files):\n",
    "#     '''\n",
    "#     DESCRIPTION:\n",
    "#         - produces a list of numpy arrays for each image in the files list.\n",
    "#     INPUT: \n",
    "#         - tot_count is the number of files to traverse through.\n",
    "#         - files is the list of image files.\n",
    "#     OUTPUT:\n",
    "#         - X is the list of numpy arrays for the clean images.\n",
    "#         - X_aug is the list of numpy arrays for the augmented images.\n",
    "#     '''\n",
    "#     X = []\n",
    "#     X_aug = []\n",
    "    \n",
    "#     if tot_count > len(files):\n",
    "#         print(\"tot_count exceeds the number of files.\")\n",
    "#         return False\n",
    "    \n",
    "#     for i in range(tot_count):\n",
    "#         # Convert the clean image\n",
    "#         clean_img = image.load_img(files[i], target_size=(224,224))\n",
    "#         clean_img = image.img_to_array(clean_img)\n",
    "#         if clean_img == None:\n",
    "#             continue\n",
    "#         X.append(clean_img)\n",
    "\n",
    "#         # Augment then convert the new image\n",
    "#         temp_imgs = augment(files[i])\n",
    "#         for temp_img in temp_imgs:\n",
    "#             if temp_img == '':\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 prep_img = image.load_img(temp_img, target_size=(224,224))\n",
    "#                 prep_img = image.img_to_array(prep_img)\n",
    "#                 if prep_img == None:\n",
    "#                     continue\n",
    "#             X_aug.append(prep_img)\n",
    "\n",
    "#     if len(X) == len(X_aug):\n",
    "#         print(\"Augmenting worked correctly.\")\n",
    "        \n",
    "#     X = np.array(X)\n",
    "#     X = preprocess_input(X)\n",
    "    \n",
    "#     X_aug = np.array(X_aug)\n",
    "#     X_aug = preprocess_input(X_aug)\n",
    "        \n",
    "#     return X, X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### NEED TO UPDATE SINCE USING DATA GENERATORS #####\n",
    "\n",
    "# def get_metrics(y_train_pred, y_test_pred, y_train, y_test):\n",
    "#     '''\n",
    "#     DESCRIPTION:\n",
    "#         - Get the various classification metrics for the training and test data.\n",
    "#     INPUT:\n",
    "#         - fit_model must be a pretrained model. \n",
    "#         - y_train_pred and y_test_pred must be one dimensional numpy arrays if binary classifier.\n",
    "#         - y_train and y_test must be one dimensional numpy arrays if binary classifier.\n",
    "#     OUTPUT:\n",
    "#         - prints the scores.\n",
    "#     '''\n",
    "#     true_pred_train = []\n",
    "#     true_pred_test = []\n",
    "    \n",
    "#     for pred1 in y_train_pred:\n",
    "#         if pred1[0] > 0.5:\n",
    "#             true_pred_train.append(1)\n",
    "#         else:\n",
    "#             true_pred_train.append(0)\n",
    "    \n",
    "#     for pred2 in y_test_pred:\n",
    "#         if pred2[0] > 0.5:\n",
    "#             true_pred_test.append(1)\n",
    "#         else:\n",
    "#             true_pred_test.append(0)\n",
    "\n",
    "#     acc_train = accuracy_score(y_train, true_pred_train)\n",
    "#     acc_test = accuracy_score(y_test, true_pred_test)\n",
    "    \n",
    "#     print(\"ACC TRAIN: \", acc_train)\n",
    "#     print(\"ACC TEST: \", acc_test)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     pre_train = precision_score(y_train, true_pred_train)\n",
    "#     pre_test = precision_score(y_test, true_pred_test)\n",
    "\n",
    "#     print(\"PRE TRAIN: \", pre_train)\n",
    "#     print(\"PRE TEST: \", pre_test)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     rec_train = recall_score(y_train, true_pred_train)\n",
    "#     rec_test = recall_score(y_test, true_pred_test)\n",
    "\n",
    "#     print(\"REC TRAIN: \", rec_train)\n",
    "#     print(\"REC TEST: \", rec_test)\n",
    "#     print(\"\\n\")    \n",
    "    \n",
    "#     f1_train = f1_score(y_train, true_pred_train)\n",
    "#     f1_test = f1_score(y_test, true_pred_test)\n",
    "\n",
    "#     print(\"F1 TRAIN: \", f1_train)\n",
    "#     print(\"F1 TEST: \", f1_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_generators(train_dir, test_dir, rescale=False, image_gen=None):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Creates the data generators for the model.\n",
    "    INPUT:\n",
    "        - If the training data needs to be augmented with more data, then set rescale to True.\n",
    "        - Also, make sure to input a valid ImageDataGenerator object.\n",
    "    OUTPUT:\n",
    "        - train_gen and test_gen are outputted\n",
    "    '''\n",
    "    if not os.path.isdir(train_dir):\n",
    "        print(\"Error: invalid train data directory.\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.isdir(test_dir):\n",
    "        print(\"Error: invalid test data directory.\")\n",
    "        return False \n",
    "    \n",
    "    if not rescale:\n",
    "        train_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "    else:\n",
    "        try:\n",
    "            train_gen = image_gen\n",
    "        except:\n",
    "            print(\"Please input a valid generator.\")\n",
    "            return False\n",
    "    test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(224,224),\n",
    "                                                  batch_size=100,\n",
    "                                                  class_mode='binary')\n",
    "    \n",
    "    test_gen = test_datagen.flow_from_directory(test_dir,\n",
    "                                                target_size=(224,224),\n",
    "                                                batch_size=100,\n",
    "                                                class_mode='binary')\n",
    "    \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape, weights='imagenet'):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Compiles the keras VGG16 model.\n",
    "    INPUT:\n",
    "        - Input shape should match the backend type:\n",
    "            - Tensorflow: (224,224,3)\n",
    "            - Theano: (3,224,224)\n",
    "    OUTPUT:\n",
    "        - final_model is outputted.\n",
    "    '''\n",
    "    model = VGG16(include_top=False, weights=weights, input_shape=input_shape)\n",
    "    last = model.output\n",
    "\n",
    "    # Freeze convolutional layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = Dropout(0.5)(last)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    preds = Activation(activation='sigmoid')(x)\n",
    "\n",
    "    final_model = Model(input=model.input, output=preds)\n",
    "\n",
    "    final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, nb_epoch, generators, model_dir):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Trains the compiled keras model,\n",
    "    INPUT:\n",
    "        - model is a compiled keras model.\n",
    "        - nb_epoch is the number of epochs to run.\n",
    "        - generators are the training and validation data generators.\n",
    "        - model_dir is the directory to save the trained model and weights.\n",
    "    OUTPUT:\n",
    "        - the trained model is outputted.\n",
    "    '''\n",
    "    train_generator, validation_generator = generators\n",
    "    \n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        epochs=nb_epoch)\n",
    "    \n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model.save(os.path.join(model_dir, 'model.h5'))\n",
    "    model.save_weights(os.path.join(model_dir,'model_weights.h5'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_model(model):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Splits the top layer of the model with the rest of the model.\n",
    "    INPUT:\n",
    "        - model should be pretrained.\n",
    "    OUTPUT:\n",
    "        - Returns the bottom_layers and a newly created top_layer.\n",
    "    '''\n",
    "    bottom_layers = model\n",
    "    bottom_layers.layers.pop()\n",
    "    bottom_layers.layers.pop()\n",
    "    inp = bottom_layers.input\n",
    "    out = bottom_layers.layers[-1].output\n",
    "\n",
    "    bottom_layers = Model(inp, out)\n",
    "    \n",
    "    top_layer = Sequential()\n",
    "    top_layer.add(Dropout(0.5, input_shape=bottom_layers.output_shape))\n",
    "    top_layer.add(Dense(1))\n",
    "    top_layer.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    top_layer.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return bottom_layers, top_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(image_1, image_2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Calculates the mean square error between two images.\n",
    "    INPUT:\n",
    "        - image_1 and image_2 are image files that are in a numpy array.\n",
    "    OUTPUT:\n",
    "        - Outputs the error (or difference) between the two images.\n",
    "    '''\n",
    "    if isinstance(image_1, numpy.ndarray) and isinstance(image_2, numpy.ndarray):\n",
    "        err = np.sum((image_1.astype(\"float\") - image_2.astype(\"float\")) ** 2)\n",
    "        err /= float(image_1.shape[0] * image_1.shape[1])\n",
    "    else:\n",
    "        print(\"Input valid numpy arrays\")\n",
    "        return False\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_frames(file_path, top_layer, bottom_layers, consecutive, path):\n",
    "#     '''\n",
    "#     DESCRIPTION:\n",
    "#         - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "#     INPUT:\n",
    "#         - file_path is a valid video file. Must be a string.\n",
    "#         - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "#         - consecutive should be the number of consecutive good photos the model needs to see before saving the photo.\n",
    "#     OUTPUT:\n",
    "#         - prints if the frame is good or bad.\n",
    "#     '''\n",
    "# #     vid = skvideo.io.VideoCapture(file_path)\n",
    "# #     vid = cv2.VideoCapture(file_path)\n",
    "#     vid = imageio.get_reader(file_path)\n",
    "#     feature_vec_list = []\n",
    "#     orig_frames = []\n",
    "#     good_frames = []\n",
    "#     curr_feat_vec = []\n",
    "    \n",
    "#     good_count = 0\n",
    "#     good_frames_count = 0\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "#             ret, frame = vid.read()\n",
    "#             if not ret:\n",
    "#                 vid.release()\n",
    "#                 print(\"Released Video Resource\")\n",
    "#                 break\n",
    "\n",
    "#             resized = np.array([cv2.resize(frame, (224, 224)).astype(np.float32)])\n",
    "#             feat_vec = bottom_layers.predict(resized)\n",
    "#             if not curr_feat_vec:\n",
    "#                 curr_feat_vec = feat_vec\n",
    "            \n",
    "#             if cosine_similarity(curr_feat_vec, feat_vec) > 0.75:\n",
    "#                 feature_vec_list.append(feat_vec)\n",
    "#                 orig_frames.append(frame)\n",
    "#             else:\n",
    "#                 pred = top_layer.predict(feature_vec_list)\n",
    "#                 if not os.path.isdir(path):\n",
    "#                     os.mkdir(path)\n",
    "                    \n",
    "#                 file_path = os.path.join(path, str(uuid.uuid4()) + '.jpg')\n",
    "#                 cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "#                 good_frames.append(orig_frames[np.argmax(pred)])\n",
    "#                 good_frames_count += 1\n",
    "#                 print(\"File Path (CHANGE SCENE): {}\".format(file_path))\n",
    "                \n",
    "#                 feature_vec_list = []\n",
    "#                 orig_frames = []\n",
    "                \n",
    "#             if len(feature_vec_list) == consecutive:\n",
    "#                 pred = top_layer.predict(feature_vec_list)\n",
    "#                 for p in pred:\n",
    "#                     if p > 0.5:\n",
    "#                         good_count += 1\n",
    "#                     else: \n",
    "#                         good_count = 0\n",
    "#                         break\n",
    "                        \n",
    "#                 if good_count == consecutive:\n",
    "#                     file_path = os.path.join(path, str(uuid.uuid4()) + '.jpg')\n",
    "#                     cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "#                     good_frames.append(orig_frames[np.argmax(pred)])\n",
    "#                     good_frames_count += 1\n",
    "#                     print(\"File Path (CONSECUTIVE): {}\".format(file_path))\n",
    "\n",
    "#                 pred_arr = []\n",
    "#                 orig_frames = []\n",
    "#         print(\"Good Frames Count: {}\".format(good_frames_count))\n",
    "                \n",
    "#         return good_frames\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         vid.release()\n",
    "#         print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames(file_path, top_layer, bottom_layers, consecutive, path):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "    INPUT:\n",
    "        - file_path is a valid video file. Must be a string.\n",
    "        - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "        - consecutive should be the number of consecutive good photos the model needs to see before saving the photo.\n",
    "    OUTPUT:\n",
    "        - prints if the frame is good or bad.\n",
    "    '''\n",
    "    try:\n",
    "        vid = imageio.get_reader(file_path)\n",
    "    except:\n",
    "        print(\"Invalid video file\")\n",
    "        return None\n",
    "    \n",
    "    feature_vec_list = []\n",
    "    orig_frames = []\n",
    "    good_frames = []\n",
    "    curr_feat_vec = []\n",
    "    \n",
    "    good_count = 0\n",
    "    good_frames_count = 0\n",
    "\n",
    "    for i in range(vid.get_length()):\n",
    "        frame = vid.get_data(i)\n",
    "\n",
    "        resized = np.array([cv2.resize(frame, (224, 224)).astype(np.float32)])\n",
    "        feat_vec = bottom_layers.predict(resized)\n",
    "        if curr_feat_vec == []:\n",
    "            curr_feat_vec = feat_vec\n",
    "\n",
    "        if cosine_similarity(curr_feat_vec, feat_vec) > 0.75:\n",
    "            feature_vec_list.append(feat_vec)\n",
    "            orig_frames.append(frame)\n",
    "        else:\n",
    "            pred = top_layer.predict(feature_vec_list)\n",
    "            if not os.path.isdir(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "            file_path = os.path.join(path, str(uuid.uuid4()) + '.jpg')\n",
    "            cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "            good_frames.append(orig_frames[np.argmax(pred)])\n",
    "            good_frames_count += 1\n",
    "            print(\"File Path (CHANGE SCENE): {}\".format(file_path))\n",
    "\n",
    "            feature_vec_list = []\n",
    "            orig_frames = []\n",
    "\n",
    "        if len(feature_vec_list) == consecutive:\n",
    "            pred = top_layer.predict(feature_vec_list)\n",
    "            for p in pred:\n",
    "                if p > 0.5:\n",
    "                    good_count += 1\n",
    "                else: \n",
    "                    good_count = 0\n",
    "                    break\n",
    "\n",
    "            if good_count == consecutive:\n",
    "                file_path = os.path.join(path, str(uuid.uuid4()) + '.jpg')\n",
    "                cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "                good_frames.append(orig_frames[np.argmax(pred)])\n",
    "                good_frames_count += 1\n",
    "                print(\"File Path (CONSECUTIVE): {}\".format(file_path))\n",
    "\n",
    "            pred_arr = []\n",
    "            orig_frames = []\n",
    "    print(\"Good Frames Count: {}\".format(good_frames_count))\n",
    "\n",
    "    return good_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instagram-scraper humansofny, humansofamsterdam, officialhumansofbombay, humansofnewtown, humansofpdx, humansofseoul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_files, aug_files = get_clean_files(['data/humansofny',\n",
    "                                          'data/humansofamsterdam',\n",
    "                                          'data/officialhumansofbombay',\n",
    "                                          'data/humansofnewtown',\n",
    "                                          'data/humansofpdx',\n",
    "                                          'data/humansofseoul'],\n",
    "                                          augment=True,\n",
    "                                          aug_file_path='data/aug_images'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 70% of images to training data, 20% of images to test data, and 10% of images to holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data_dir = ['data/train_data/clean','data/test_data/clean','data/holdout_data/clean']\n",
    "aug_data_dir = ['data/train_data/aug','data/test_data/aug','data/holdout_data/aug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success_clean = move_files(clean_files,\n",
    "                           [0.7,0.2,0.1],\n",
    "                           clean_data_dir)\n",
    "\n",
    "success_aug = move_files(aug_files,\n",
    "                         [0.7,0.2,0.1],\n",
    "                         aug_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn images into an image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22021 images belonging to 2 classes.\n",
      "Found 7786 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generators = get_generators(rescale=False, \n",
    "                            image_gen=None, \n",
    "                            train_dir='data/train_data', \n",
    "                            test_dir='data/test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plim0793/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 166s - loss: 0.2537 - acc: 0.9052 - val_loss: 0.1171 - val_acc: 0.9610\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 165s - loss: 0.0905 - acc: 0.9772 - val_loss: 0.0863 - val_acc: 0.9770\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 164s - loss: 0.0652 - acc: 0.9842 - val_loss: 0.0795 - val_acc: 0.9700\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 165s - loss: 0.0577 - acc: 0.9855 - val_loss: 0.0715 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 164s - loss: 0.0507 - acc: 0.9873 - val_loss: 0.0827 - val_acc: 0.9740\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 165s - loss: 0.0440 - acc: 0.9888 - val_loss: 0.0767 - val_acc: 0.9750\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 164s - loss: 0.0428 - acc: 0.9883 - val_loss: 0.0530 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 165s - loss: 0.0377 - acc: 0.9903 - val_loss: 0.0488 - val_acc: 0.9830\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 164s - loss: 0.0360 - acc: 0.9909 - val_loss: 0.0589 - val_acc: 0.9820\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 166s - loss: 0.0319 - acc: 0.9924 - val_loss: 0.0469 - val_acc: 0.9830\n"
     ]
    }
   ],
   "source": [
    "model = get_model(input_shape=(224,224,3))\n",
    "fit_model = train_model(model,\n",
    "                        nb_epoch=10,\n",
    "                        generators=generators,\n",
    "                        model_dir='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split model into top layer and other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot, top = split_model(model=keras.models.load_model('data/model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE GET_FRAMES: \n",
      "2017-06-18 00:33:20.882983\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE GET_FRAMES: \")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plim0793/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:31: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 arrays but instead got the following list of 10 arrays: [array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  3.4589026,\n         0.       ]], dtype=float32), array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  3.4589026,\n         0.    ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-bdfe5a07f2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mbottom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mconsecutive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   path='data/good_photos')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AFTER GET_FRAMES: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-664b1e9c1fea>\u001b[0m in \u001b[0;36mget_frames\u001b[0;34m(file_path, top_layer, bottom_layers, consecutive, path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vec_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconsecutive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vec_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                  \u001b[0;34m'the following list of '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                  \u001b[0;34m' arrays: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                  '...')\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 arrays but instead got the following list of 10 arrays: [array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  3.4589026,\n         0.       ]], dtype=float32), array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  3.4589026,\n         0.    ..."
     ]
    }
   ],
   "source": [
    "snap = get_frames(\"data/humansofamsterdam/15147725_796232163848807_1530264403381846016_n.mp4\",\n",
    "                  top_layer=top,\n",
    "                  bottom_layers=bot,\n",
    "                  consecutive=10,\n",
    "                  path='data/good_photos')\n",
    "print(\"AFTER GET_FRAMES: \")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 25088)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imageio.core.util.Image"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in v:\n",
    "    v.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_photos = cv2.cvtColor(snap[2], cv2.COLOR_BGR2BGRA)\n",
    "plt.imshow(good_photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse(snap[0],snap[5])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
