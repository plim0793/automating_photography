{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "('BACKEND: ', u'tensorflow')\n"
     ]
    }
   ],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions, preprocess_input\n",
    "from keras.applications import InceptionV3, ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#### SKLEARN IMPORTS ####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import re\n",
    "import skvideo.io\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "% pylab inline\n",
    "% matplotlib inline\n",
    "\n",
    "print(\"BACKEND: \", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image_path, repeat=5):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "    img_paths = []\n",
    "    \n",
    "    for i in range(repeat):\n",
    "        new_dim = int(img_arr.shape[1] * np.random.uniform(low=0.1, high=0.3))\n",
    "        new_img_arr = resize_img(img_arr, new_dim)\n",
    "\n",
    "        deg = np.random.randint(15, 345)\n",
    "        scale = np.random.uniform(low=1, high=4)\n",
    "        new_img_arr = rotate_img(new_img_arr, deg, scale)\n",
    "\n",
    "        lower_height = np.random.randint(15, new_img_arr.shape[0])\n",
    "        lower_width = np.random.randint(15, new_img_arr.shape[1])\n",
    "        upper_height = np.random.randint(lower_height, 10000)\n",
    "        upper_width = np.random.randint(lower_width, 10000)\n",
    "\n",
    "        new_img_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "\n",
    "        new_img_path = 'data/aug_images/' + 'aug_' + str(i) + \"_\" + re.sub(r\"data/[a-zA-Z]*/\", '', image_path)\n",
    "\n",
    "        new_img = cv2.imwrite(new_img_path, new_img_arr)\n",
    "        img_paths.append(new_img_path)\n",
    "        if not new_img:\n",
    "            print(\"Check image path: \", new_img_path)\n",
    "            img_paths.append('')\n",
    "    \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_files(file_paths, perc, dest):\n",
    "    new_file_paths = int(len(file_paths) * perc) - 1\n",
    "    count = 0\n",
    "    cycle_count = 0\n",
    "    for f in file_paths:\n",
    "        if os.path.isfile(f):\n",
    "            shutil.move(f, dest)\n",
    "            count += 1\n",
    "        if count == new_file_paths:\n",
    "            return count\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_aug_arrays(tot_count, files):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - produces a list of numpy arrays for each image in the files list.\n",
    "    INPUT: \n",
    "        - tot_count is the number of files to traverse through.\n",
    "        - files is the list of image files.\n",
    "    OUTPUT:\n",
    "        - X is the list of numpy arrays for the clean images.\n",
    "        - X_aug is the list of numpy arrays for the augmented images.\n",
    "    '''\n",
    "    X = []\n",
    "    X_aug = []\n",
    "    \n",
    "    if tot_count > len(files):\n",
    "        print(\"tot_count exceeds the number of files.\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(tot_count):\n",
    "        # Convert the clean image\n",
    "        clean_img = image.load_img(files[i], target_size=(224,224))\n",
    "        clean_img = image.img_to_array(clean_img)\n",
    "        if clean_img == None:\n",
    "            continue\n",
    "        X.append(clean_img)\n",
    "\n",
    "        # Augment then convert the new image\n",
    "        temp_imgs = augment(files[i])\n",
    "        for temp_img in temp_imgs:\n",
    "            if temp_img == '':\n",
    "                continue\n",
    "            else:\n",
    "                prep_img = image.load_img(temp_img, target_size=(224,224))\n",
    "                prep_img = image.img_to_array(prep_img)\n",
    "                if prep_img == None:\n",
    "                    continue\n",
    "            X_aug.append(prep_img)\n",
    "\n",
    "    if len(X) == len(X_aug):\n",
    "        print(\"Augmenting worked correctly.\")\n",
    "        \n",
    "    X = np.array(X)\n",
    "    X = preprocess_input(X)\n",
    "    \n",
    "    X_aug = np.array(X_aug)\n",
    "    X_aug = preprocess_input(X_aug)\n",
    "        \n",
    "    return X, X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_train_pred, y_test_pred, y_train, y_test):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Get the various classification metrics for the training and test data.\n",
    "    INPUT:\n",
    "        - fit_model must be a pretrained model. \n",
    "        - y_train_pred and y_test_pred must be one dimensional numpy arrays if binary classifier.\n",
    "        - y_train and y_test must be one dimensional numpy arrays if binary classifier.\n",
    "    OUTPUT:\n",
    "        - prints the scores.\n",
    "    '''\n",
    "    true_pred_train = []\n",
    "    true_pred_test = []\n",
    "    \n",
    "    for pred1 in y_train_pred:\n",
    "        if pred1[0] > 0.5:\n",
    "            true_pred_train.append(1)\n",
    "        else:\n",
    "            true_pred_train.append(0)\n",
    "    \n",
    "    for pred2 in y_test_pred:\n",
    "        if pred2[0] > 0.5:\n",
    "            true_pred_test.append(1)\n",
    "        else:\n",
    "            true_pred_test.append(0)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, true_pred_train)\n",
    "    acc_test = accuracy_score(y_test, true_pred_test)\n",
    "    \n",
    "    print(\"ACC TRAIN: \", acc_train)\n",
    "    print(\"ACC TEST: \", acc_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    pre_train = precision_score(y_train, true_pred_train)\n",
    "    pre_test = precision_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"PRE TRAIN: \", pre_train)\n",
    "    print(\"PRE TEST: \", pre_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    rec_train = recall_score(y_train, true_pred_train)\n",
    "    rec_test = recall_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"REC TRAIN: \", rec_train)\n",
    "    print(\"REC TEST: \", rec_test)\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    f1_train = f1_score(y_train, true_pred_train)\n",
    "    f1_test = f1_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"F1 TRAIN: \", f1_train)\n",
    "    print(\"F1 TEST: \", f1_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(image_1, image_2):\n",
    "    err = np.sum((image_1.astype(\"float\") - image_2.astype(\"float\")) ** 2)\n",
    "    err /= float(image_1.shape[0] * image_1.shape[1])\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames(file_path, model, consecutive, err_threshold):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "    INPUT:\n",
    "        - file_path is a valid video file. Must be a string.\n",
    "        - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "        - consecutive should be the number of consecutive good photos the model needs to see before saving the photo.\n",
    "    OUTPUT:\n",
    "        - prints if the frame is good or bad.\n",
    "    '''\n",
    "    vid = skvideo.io.VideoCapture(file_path)\n",
    "#     vid = cv2.VideoCapture(file_path)\n",
    "    pred_arr = []\n",
    "    orig_frames = []\n",
    "    good_frames = []\n",
    "    \n",
    "    good_count = 0\n",
    "    good_frames_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = vid.read()\n",
    "            if not ret:\n",
    "                vid.release()\n",
    "                print(\"Released Video Resource\")\n",
    "                break\n",
    "\n",
    "            resized = cv2.resize(frame, (224, 224)).astype(np.float32)\n",
    "            if not pred_arr:\n",
    "                pred_arr.append(resized)\n",
    "                orig_frames.append(frame)\n",
    "            \n",
    "            for image in pred_arr:\n",
    "                err = mse(image, resized)\n",
    "                if err > err_threshold:\n",
    "                    pred_arr.append(resized)\n",
    "                    orig_frames.append(frame)\n",
    "                    break\n",
    "                \n",
    "            if len(pred_arr) >= consecutive:\n",
    "                pred_arr = np.array(pred_arr)\n",
    "                pred = model.predict(pred_arr)\n",
    "                for p in pred:\n",
    "                    if p > 0.5:\n",
    "                        good_count += 1\n",
    "                    else: \n",
    "                        good_count = 0\n",
    "                        break\n",
    "\n",
    "                if good_count == consecutive:\n",
    "                    print(\"PRED_ARR SHAPE: \", orig_frames[consecutive // 2].shape)\n",
    "                    file_path = 'data/good_photos/' + str(good_frames_count) + '.jpg'\n",
    "                    print(\"File Path: \", file_path)\n",
    "                    cv2.imwrite(file_path, orig_frames[consecutive // 2])\n",
    "                    \n",
    "                    good_frames.append(orig_frames[consecutive // 2])\n",
    "                    good_frames_count += 1\n",
    "\n",
    "                pred_arr = []\n",
    "                orig_frames = []\n",
    "                \n",
    "        return good_frames\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        vid.release()\n",
    "        print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get a list of filenames corresponding to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instagram-scraper humansofny, humansofamsterdam, officialhumansofbombay, humansofnewtown, humansofpdx, humansofseoul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ny = ['data/humansofny/' + f for f in listdir('data/humansofny/') if isfile(join('data/humansofny/', f))]\n",
    "am = ['data/humansofamsterdam/' + f for f in listdir('data/humansofamsterdam/') if isfile(join('data/humansofamsterdam/', f))]\n",
    "bo = ['data/officialhumansofbombay/' + f for f in listdir('data/officialhumansofbombay/') if isfile(join('data/officialhumansofbombay/', f))]\n",
    "nt = ['data/humansofnewtown/' + f for f in listdir('data/humansofnewtown/') if isfile(join('data/humansofnewtown/', f))]\n",
    "pd = ['data/humansofpdx/' + f for f in listdir('data/humansofpdx/') if isfile(join('data/humansofpdx/', f))]\n",
    "se = ['data/humansofseoul/' + f for f in listdir('data/humansofseoul/') if isfile(join('data/humansofseoul/', f))]\n",
    "\n",
    "files = ny + am + bo + nt + pd + se\n",
    "clean_files = [loc for loc in files if '.mp4' not in loc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create \"bad\" images by resizing, rotating, and cropping the \"good\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mkdir data/aug_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file_path in clean_files:\n",
    "    aug_im_paths = augment(file_path, repeat=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aug_files = ['data/aug_images/' + f for f in listdir('data/aug_images/') if isfile(join('data/aug_images/', f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 70% of images to training data, 20% of images to test data, and 10% of images to holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mkdir data/train_data/clean\n",
    "# mkdir data/test_data/clean\n",
    "# mkdir data/holdout_data/clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean = move_files(clean_files, 0.7, 'data/train_data/clean')\n",
    "test_clean = move_files(clean_files, 0.2, 'data/test_data/clean')\n",
    "holdout_clean = move_files(clean_files, 0.1, 'data/holdout_data/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mkdir data/train_data/aug\n",
    "# mkdir data/test_data/aug\n",
    "# mkdir data/holdout_data/aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_aug = move_files(aug_files, 0.7, 'data/train_data/aug')\n",
    "test_aug = move_files(aug_files, 0.2, 'data/test_data/aug')\n",
    "holdout_aug = move_files(aug_files, 0.1, 'data/holdout_data/aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn images into an image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_gen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22022 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = img_gen.flow_from_directory('data/train_data/',\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=100,\n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6289 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = img_gen.flow_from_directory('data/test_data/',\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=100,\n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tot_count = int(len(clean_files) * 1)\n",
    "# X, X_aug = get_clean_aug_arrays(tot_count, clean_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joblib.dump(X, 'data/X.pkl')\n",
    "# joblib.dump(X_aug, 'data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = joblib.load('data/X.pkl')\n",
    "# X_aug = joblib.load('data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = [1 for _ in range(len(X))]\n",
    "# y_aug = [0 for _ in range(len(X_aug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_tot = np.append(X, X_aug, axis=0)\n",
    "# y_tot = np.append(y, y_aug, axis=0).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_tot, y_tot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape((3470, 224, 224, 3))\n",
    "# X_test = X_test.reshape((868, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res1_arr = cv2.imread('data/train_data/clean/13525267_1805082676390077_131474524_n.jpg')\n",
    "res1_arr = cv2.resize(res1_arr, (224,224))\n",
    "\n",
    "res2_arr = cv2.imread('data/train_data/clean/929227_1481650375443373_322000989_n.jpg')\n",
    "res2_arr = cv2.resize(res2_arr, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input is the np array of an image. Outputs a (None, 4096) vector\n",
    "first_model = VGG16(include_top=True, weights='imagenet', input_shape=(224,224,3))\n",
    "first_model.layers.pop()\n",
    "first_model.outputs = [first_model.layers[-1].output]\n",
    "first_model.layers[-1].outbound_nodes = []\n",
    "\n",
    "pred = first_model.predict(np.array([res1_arr, res2_arr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input is the (None, 4096) vector from the first model. Outputs \"good\" or \"bad\".\n",
    "second_model = Sequential()\n",
    "second_model.add(Dropout(0.5, input_shape=(4096,)))\n",
    "second_model.add(Dense(1))\n",
    "second_model.add(Activation(activation='sigmoid'))\n",
    "\n",
    "second_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_model.predict(np.array([pred[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=True, weights='imagenet', input_shape=(224,224,3))\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.layers[-1].outbound_nodes = []\n",
    "last = model.output\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Dropout(0.5)(last)\n",
    "# x = Flatten()(x)\n",
    "x = Dense(1)(x)\n",
    "preds = Activation(activation='sigmoid')(x)\n",
    "\n",
    "final_model = Model(input=model.input, output=preds)\n",
    "\n",
    "final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 1000)          4097000     fc2[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 1000)          0           predictions[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             1001        dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1)             0           dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 138,358,545\n",
      "Trainable params: 4,098,001\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.utils.layer_utils.print_summary(final_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "final_model.fit_generator(train_generator,\n",
    "                          samples_per_epoch= 22022 // 10,\n",
    "                          nb_epoch=15,\n",
    "                          validation_data=validation_generator,\n",
    "                          nb_val_samples=6290 // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = final_model.evaluate(X_test, y_test, batch_size=100)\n",
    "print(\"TEST SCORE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_metrics(y_pred_train, y_pred_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save('data/final_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights('data/final_model_weights2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_model = keras.models.load_model('data/final_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_train = final_model.predict_generator(validation_generator, 6290 // 10)\n",
    "y_pred_test = final_model.predict_generator(validation_generator, 6290 // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"BEFORE GET_FRAMES: \")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "snap = get_frames(\"data/humansofnewtown/17412197_1501706763213585_979301789583015936_n.mp4\",\n",
    "                  model=final_model,\n",
    "                  consecutive=5,\n",
    "                  err_threshold=3000)\n",
    "print(\"AFTER GET_FRAMES: \")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_photos = cv2.cvtColor(snap[2], cv2.COLOR_BGR2BGRA)\n",
    "plt.imshow(good_photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse(snap[0],snap[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = '/home/icarus/git/automating_photography/flask_app/src/static/images/10.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = re.search('[0-9]*.jpg', s)\n",
    "l.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
