{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import datetime\n",
    "import shutil\n",
    "import uuid\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import imageio\n",
    "import logging\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "% pylab inline\n",
    "% matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"BACKEND: {}\".format(str(keras.backend.backend())))\n",
    "\n",
    "handler = logging.FileHandler('logging_records.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def use_instagram_scraper(list_of_directories):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Use instagram-scraper to scrape images from instagram.\n",
    "    INPUT:\n",
    "        - list_of_directories is the directories associated with the usernames to scrape from.\n",
    "    OUTPUT:\n",
    "        - The output is the updated list_of_directories.\n",
    "    '''\n",
    "    for directory in list_of_directories:\n",
    "        try:\n",
    "            username = re.sub('data/','',directory)\n",
    "            username = re.sub('/', '', username)\n",
    "            subprocess.call(['instagram-scraper', '-d', directory, username])\n",
    "            logger.info(\"username: {}\".format(str(username)))\n",
    "        except:\n",
    "            logger.error(\"Could not scrape into {}\".format(str(directory)))\n",
    "            list_of_usernames_directories.remove(directory)\n",
    "            \n",
    "    return list_of_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blur_img(orig_img, size=15):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - blurs the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - size dictates the amount of blurring\n",
    "    OUTPUT:\n",
    "        - blurred_img is a numpy array of the blurred image.\n",
    "    '''\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "    \n",
    "    blurred_img = cv2.filter2D(orig_img, -1, kernel_motion_blur)\n",
    "    \n",
    "    return blurred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image_path, new_path, repeat=5):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - repeat is an integer value stating the number of augmented images per clean image.\n",
    "        - new_path is the relative directory to save the augmented images to.\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "    img_paths = []\n",
    "    \n",
    "    for _ in range(repeat):\n",
    "        if img_arr is None:\n",
    "            continue\n",
    "        blurred_arr = blur_img(img_arr, size=np.random.randint(10,30))\n",
    "\n",
    "        deg = np.random.randint(15, 345)\n",
    "        scale = np.random.uniform(low=1, high=3)\n",
    "        new_img_arr = rotate_img(blurred_arr, deg, scale)\n",
    "        \n",
    "        if new_img_arr.shape[0] <= 100 or new_img_arr.shape[1] <= 100:\n",
    "            lower_height = new_img_arr.shape[0] - 1\n",
    "            lower_width = new_img_arr.shape[1] - 1\n",
    "        else:\n",
    "            lower_height = np.random.randint(100, new_img_arr.shape[0])\n",
    "            lower_width = np.random.randint(100, new_img_arr.shape[1])\n",
    "        upper_height = np.random.randint(lower_height, 10000)\n",
    "        upper_width = np.random.randint(lower_width, 10000)\n",
    "        \n",
    "        cropped_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "        \n",
    "        if not os.path.isdir(new_path):\n",
    "            os.makedirs(new_path)\n",
    "            logger.info(\"Created {} directory\".format(str(new_path)))\n",
    "            \n",
    "        cropped_img_path = os.path.join(new_path, str(uuid.uuid4()) + '.jpg')\n",
    "        cropped_img = cv2.imwrite(cropped_img_path, cropped_arr)\n",
    "        \n",
    "        if not cropped_img:\n",
    "            logger.info(\"Check image path: {}\".format(str(cropped_img_path)))\n",
    "            if os.path.isfile(cropped_img_path):\n",
    "                os.remove(cropped_img_path)\n",
    "            continue\n",
    "        img_paths.append(cropped_img_path)\n",
    "    \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(paths, with_augment=False, aug_file_path=None):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Generates the list of image file paths.\n",
    "    INPUT:\n",
    "        - paths is an iterable object with valid directories.\n",
    "        - If augment is True, then the images in the paths are augmented.\n",
    "            - aug_file_path must also be specified.\n",
    "    OUTPUT:\n",
    "        - If augment is True, then clean_files is a list of clean image file paths \n",
    "          and aug_files is a list of augmented file paths.\n",
    "        - If augment is False, then only one list of file paths are given.\n",
    "    '''\n",
    "    clean_files = []\n",
    "    for path in paths:\n",
    "        if os.path.isdir(path):\n",
    "            clean_files += [path + f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "        else:\n",
    "            logger.error(\"{} is invalid.\".format(str(path)))\n",
    "            \n",
    "    if with_augment:\n",
    "        if aug_file_path:\n",
    "            if not os.path.isdir(aug_file_path):\n",
    "                os.makedirs(aug_file_path)\n",
    "            aug_files = []\n",
    "            for item in clean_files:\n",
    "                aug_img = augment(item, repeat=5, new_path=aug_file_path)\n",
    "                \n",
    "            aug_files = [aug_file_path + f for f in os.listdir(aug_file_path) if os.path.isfile(os.path.join(aug_file_path, f))]\n",
    "            return clean_files, aug_files\n",
    "    else:\n",
    "        logger.error(\"Enter in a directory to save augmented images.\")\n",
    "        return clean_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_files(file_paths, perc_list, dir_list):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Moves files to specific directories.\n",
    "    INPUT:\n",
    "        - file_paths is an iterable object with valid file paths.\n",
    "        - perc_list is an iterable object with floats that sum to 1.\n",
    "        - dir_list\n",
    "    OUTPUT:\n",
    "        - If augment is True, then clean_files is a list of clean image file paths \n",
    "          and aug_files is a list of augmented file paths.\n",
    "        - If augment is False, then only one list of file paths are given.\n",
    "    '''\n",
    "    if len(perc_list) > len(dir_list):\n",
    "        logger.warning(\"Warning: more percentages ({}) than available directories ({})\".format(str(len(perc_list)), str(len(dir_list))))\n",
    "    \n",
    "    if len(perc_list) < len(dir_list):\n",
    "        logger.error(\"Error: Too few percentages.\")\n",
    "        return False\n",
    "    \n",
    "    for i, d in enumerate(dir_list):\n",
    "        if not os.path.isdir(d):\n",
    "            os.makedirs(d)\n",
    "        \n",
    "        num_files = int(len(file_paths) * perc_list[i]) - 1\n",
    "        count = 0\n",
    "        cycle_count = 0\n",
    "        for f in file_paths:\n",
    "            if os.path.isfile(f):\n",
    "                shutil.move(f, d)\n",
    "                count += 1\n",
    "                \n",
    "            if count == num_files:\n",
    "                break\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generators(train_dir, test_dir, rescale=False, image_gen=None):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Creates the data generators for the model.\n",
    "    INPUT:\n",
    "        - If the training data needs to be augmented with more data, then set rescale to True.\n",
    "        - Also, make sure to input a valid ImageDataGenerator object.\n",
    "    OUTPUT:\n",
    "        - train_gen and test_gen are outputted\n",
    "    '''\n",
    "    if not os.path.isdir(train_dir):\n",
    "        logger.error(\"Error: invalid train data directory.\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.isdir(test_dir):\n",
    "        logger.error(\"Error: invalid test data directory.\")\n",
    "        return False \n",
    "    \n",
    "    if not rescale:\n",
    "        train_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "    else:\n",
    "        try:\n",
    "            train_gen = image_gen\n",
    "        except:\n",
    "            logger.error(\"Please input a valid generator.\")\n",
    "            return False\n",
    "    test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                                  target_size=(224,224),\n",
    "                                                  batch_size=100,\n",
    "                                                  class_mode='binary')\n",
    "    \n",
    "    test_gen = test_datagen.flow_from_directory(test_dir,\n",
    "                                                target_size=(224,224),\n",
    "                                                batch_size=100,\n",
    "                                                class_mode='binary')\n",
    "    \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(input_shape, weights='imagenet'):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Compiles the keras VGG16 model.\n",
    "    INPUT:\n",
    "        - Input shape should match the backend type:\n",
    "            - Tensorflow: (224,224,3)\n",
    "            - Theano: (3,224,224)\n",
    "    OUTPUT:\n",
    "        - final_model is outputted.\n",
    "    '''\n",
    "    model = VGG16(include_top=False, weights=weights, input_shape=input_shape)\n",
    "    last = model.output\n",
    "\n",
    "    # Freeze convolutional layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = Dropout(0.5)(last)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    preds = Activation(activation='sigmoid')(x)\n",
    "\n",
    "    final_model = Model(input=model.input, output=preds)\n",
    "\n",
    "    final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, nb_epoch, generators, model_dir):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Trains the compiled keras model,\n",
    "    INPUT:\n",
    "        - model is a compiled keras model.\n",
    "        - nb_epoch is the number of epochs to run.\n",
    "        - generators are the training and validation data generators.\n",
    "        - model_dir is the directory to save the trained model and weights.\n",
    "    OUTPUT:\n",
    "        - the trained model is outputted.\n",
    "    '''\n",
    "    train_generator, validation_generator = generators\n",
    "    \n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        epochs=nb_epoch)\n",
    "    \n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    model.save(os.path.join(model_dir, 'model.h5'))\n",
    "    model.save_weights(os.path.join(model_dir,'model_weights.h5'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_model(model):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Splits the top layer of the model with the rest of the model.\n",
    "    INPUT:\n",
    "        - model should be pretrained.\n",
    "    OUTPUT:\n",
    "        - Returns the bottom_layers and a newly created top_layer.\n",
    "    '''\n",
    "    bottom_layers = model\n",
    "    bottom_layers.layers.pop()\n",
    "    bottom_layers.layers.pop()\n",
    "    inp = bottom_layers.input\n",
    "    out = bottom_layers.layers[-1].output\n",
    "\n",
    "    bottom_layers = Model(inp, out)\n",
    "    \n",
    "    top_layer = Sequential()\n",
    "    top_layer.add(Dropout(0.5, input_shape=bottom_layers.output_shape))\n",
    "    top_layer.add(Dense(1))\n",
    "    top_layer.add(Activation(activation='sigmoid'))\n",
    "\n",
    "    top_layer.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return bottom_layers, top_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames(file_path, top_layer, bottom_layers, path, sim_threshold, good_threshold, consecutive):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "    INPUT:\n",
    "        - file_path is a valid video file. Must be a string.\n",
    "        - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "        - consecutive should be the number of consecutive good photos the model needs to see before saving the photo.\n",
    "    OUTPUT:\n",
    "        - prints if the frame is good or bad.\n",
    "    '''\n",
    "    try:\n",
    "        vid = imageio.get_reader(file_path)\n",
    "    except:\n",
    "        logger.error(\"Invalid video file\")\n",
    "        return None\n",
    "    \n",
    "    feature_vec_list = []\n",
    "    orig_frames = []\n",
    "    good_frames = []\n",
    "    curr_feat_vec = []\n",
    "    \n",
    "    frame_count = 0\n",
    "    good_count = 0\n",
    "    good_frames_count = 0\n",
    "    \n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "        \n",
    "    os.makedirs(path)\n",
    "\n",
    "    for i in range(vid.get_length()):\n",
    "        try:\n",
    "            frame = vid.get_data(i)\n",
    "        except:\n",
    "            logger.warning(\"Frame could not be read.\")\n",
    "            continue\n",
    "\n",
    "        resized = np.array([cv2.resize(frame, (224, 224)).astype(np.float32)])\n",
    "        feat_vec = bottom_layers.predict(resized)\n",
    "        \n",
    "        if curr_feat_vec == []:\n",
    "            curr_feat_vec = feat_vec\n",
    "\n",
    "        if cosine_similarity(curr_feat_vec, feat_vec) > sim_threshold or len(feature_vec_list) == 0:\n",
    "            feature_vec_list.append(feat_vec)\n",
    "            orig_frames.append(frame)\n",
    "            curr_feat_vec = feat_vec\n",
    "            if len(feature_vec_list) == consecutive:\n",
    "                logger.info(\"LENGTH OF CURRENT SCENE (CONSECUTIVE): {}\".format(str(len(feature_vec_list))))\n",
    "                pred = top_layer.predict(np.array(feature_vec_list))\n",
    "                if pred[np.argmax(pred)] < good_threshold:\n",
    "                    feature_vec_list = []\n",
    "                    orig_frames = []\n",
    "                    continue\n",
    "                if good_frames_count < 10:\n",
    "                    file_path = os.path.join(path, \"000\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                elif good_frames_count < 100:\n",
    "                    file_path = os.path.join(path, \"00\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                else:\n",
    "                    file_path = os.path.join(path, \"0\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                orig_frames[np.argmax(pred)] = cv2.cvtColor(orig_frames[np.argmax(pred)], cv2.COLOR_RGB2BGR)    \n",
    "                cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "                good_frames.append(orig_frames[np.argmax(pred)])\n",
    "                good_frames_count += 1\n",
    "\n",
    "                pred = np.delete(pred, np.argmax(pred))\n",
    "                logger.info(\"File Path: {}\".format(str(file_path)))\n",
    "                feature_vec_list = []\n",
    "                orig_frames = []\n",
    "        else:\n",
    "            logger.info(\"LENGTH OF CURRENT SCENE (CHANGE): {}\".format(str(len(feature_vec_list))))\n",
    "            pred = top_layer.predict(np.array(feature_vec_list))\n",
    "            if pred[np.argmax(pred)] < good_threshold:\n",
    "                feature_vec_list = []\n",
    "                orig_frames = []\n",
    "                continue\n",
    "            if good_frames_count < 10:\n",
    "                file_path = os.path.join(path, \"000\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            elif good_frames_count < 100:\n",
    "                file_path = os.path.join(path, \"00\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            else:\n",
    "                file_path = os.path.join(path, \"0\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            \n",
    "            orig_frames[np.argmax(pred)] = cv2.cvtColor(orig_frames[np.argmax(pred)], cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(file_path, orig_frames[np.argmax(pred)])\n",
    "            good_frames.append(orig_frames[np.argmax(pred)])\n",
    "            good_frames_count += 1\n",
    "\n",
    "            pred = np.delete(pred, np.argmax(pred))\n",
    "            logger.info(\"File Path: {}\".format(str(file_path)))\n",
    "\n",
    "            feature_vec_list = []\n",
    "            orig_frames = []\n",
    "\n",
    "    logger.info(\"Good Frames Count: {}\".format(str(good_frames_count)))\n",
    "\n",
    "    return good_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bad_frames(file_path, top_layer, bottom_layers, path, sim_threshold, bad_threshold, consecutive):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "    INPUT:\n",
    "        - file_path is a valid video file. Must be a string.\n",
    "        - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "        - consecutive should be the number of consecutive good photos the model needs to see before saving the photo.\n",
    "    OUTPUT:\n",
    "        - prints if the frame is good or bad.\n",
    "    '''\n",
    "    try:\n",
    "        vid = imageio.get_reader(file_path)\n",
    "    except:\n",
    "        logger.error(\"Invalid video file\")\n",
    "        return None\n",
    "    \n",
    "    feature_vec_list = []\n",
    "    orig_frames = []\n",
    "    good_frames = []\n",
    "    curr_feat_vec = []\n",
    "    \n",
    "    frame_count = 0\n",
    "    good_count = 0\n",
    "    good_frames_count = 0\n",
    "    \n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "        \n",
    "    os.makedirs(path)\n",
    "\n",
    "    for i in range(vid.get_length()):\n",
    "        try:\n",
    "            frame = vid.get_data(i)\n",
    "        except:\n",
    "            logger.warning(\"Frame could not be read.\")\n",
    "            continue\n",
    "\n",
    "        resized = np.array([cv2.resize(frame, (224, 224)).astype(np.float32)])\n",
    "        feat_vec = bottom_layers.predict(resized)\n",
    "        \n",
    "        if curr_feat_vec == []:\n",
    "            curr_feat_vec = feat_vec\n",
    "\n",
    "        if cosine_similarity(curr_feat_vec, feat_vec) > sim_threshold or len(feature_vec_list) == 0:\n",
    "            feature_vec_list.append(feat_vec)\n",
    "            orig_frames.append(frame)\n",
    "            curr_feat_vec = feat_vec\n",
    "            if len(feature_vec_list) == consecutive:\n",
    "                logger.info(\"LENGTH OF CURRENT SCENE (CONSECUTIVE): {}\".format(str(len(feature_vec_list))))\n",
    "                pred = top_layer.predict(np.array(feature_vec_list))\n",
    "                if pred[np.argmin(pred)] > bad_threshold:\n",
    "                    feature_vec_list = []\n",
    "                    orig_frames = []\n",
    "                    continue\n",
    "                if good_frames_count < 10:\n",
    "                    file_path = os.path.join(path, \"000\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                elif good_frames_count < 100:\n",
    "                    file_path = os.path.join(path, \"00\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                else:\n",
    "                    file_path = os.path.join(path, \"0\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "                orig_frames[np.argmin(pred)] = cv2.cvtColor(orig_frames[np.argmin(pred)], cv2.COLOR_RGB2BGR)    \n",
    "                cv2.imwrite(file_path, orig_frames[np.argmin(pred)])\n",
    "                good_frames.append(orig_frames[np.argmin(pred)])\n",
    "                good_frames_count += 1\n",
    "\n",
    "                pred = np.delete(pred, np.argmin(pred))\n",
    "                logger.info(\"File Path: {}\".format(str(file_path)))\n",
    "                feature_vec_list = []\n",
    "                orig_frames = []\n",
    "        else:\n",
    "            logger.info(\"LENGTH OF CURRENT SCENE (CHANGE): {}\".format(str(len(feature_vec_list))))\n",
    "            pred = top_layer.predict(np.array(feature_vec_list))\n",
    "            if pred[np.argmin(pred)] > bad_threshold:\n",
    "                feature_vec_list = []\n",
    "                orig_frames = []\n",
    "                continue\n",
    "            if good_frames_count < 10:\n",
    "                file_path = os.path.join(path, \"000\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            elif good_frames_count < 100:\n",
    "                file_path = os.path.join(path, \"00\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            else:\n",
    "                file_path = os.path.join(path, \"0\" + str(good_frames_count) + \"_\" + str(uuid.uuid4()) + '.jpg')\n",
    "            \n",
    "            orig_frames[np.argmin(pred)] = cv2.cvtColor(orig_frames[np.argmin(pred)], cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(file_path, orig_frames[np.argmin(pred)])\n",
    "            good_frames.append(orig_frames[np.argmin(pred)])\n",
    "            good_frames_count += 1\n",
    "\n",
    "            pred = np.delete(pred, np.argmin(pred))\n",
    "            logger.info(\"File Path: {}\".format(str(file_path)))\n",
    "\n",
    "            feature_vec_list = []\n",
    "            orig_frames = []\n",
    "\n",
    "    logger.info(\"Good Frames Count: {}\".format(str(good_frames_count)))\n",
    "\n",
    "    return good_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_images_from_folder(folder):\n",
    "    images = []\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIST_OF_USERNAME_DIRECTORIES = ['data/earthpix/',\n",
    "                                 'data/beautifuldestinations/',\n",
    "                                 'data/vsco/',\n",
    "                                 'data/humansofamsterdam/',\n",
    "                                 'data/officialhumansofbombay/',\n",
    "                                 'data/humansofnewtown/',\n",
    "                                 'data/humansofny/',\n",
    "                                 'data/humansofpdx/',\n",
    "                                 'data/humansofseoul/',\n",
    "                                 'data/citiesofmyworld/',\n",
    "                                 'data/beautifullpllaces/',\n",
    "                                 'data/wonderful_places/']\n",
    "\n",
    "AUG_FILE_DIR = 'data/aug_images/'\n",
    "\n",
    "CLEAN_DATA_DIR = ['data/train_data/clean/','data/test_data/clean/','data/holdout_data/clean/']\n",
    "AUG_DATA_DIR = ['data/train_data/aug/','data/test_data/aug/','data/holdout_data/aug/']\n",
    "\n",
    "TRAIN_DIR = 'data/train_data'\n",
    "TEST_DIR = 'data/test_data'\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "VID_PATH = 'data/try2.MOV'\n",
    "GOOD_PATH = 'data/good_photos/try2/'\n",
    "BAD_PATH = 'data/good_photos/try2_bad/'\n",
    "\n",
    "SIM_THRESHOLD = 0.50\n",
    "GOOD_THRESHOLD = 0.999\n",
    "BAD_THRESHOLD = 0.1\n",
    "CONSECUTIVE = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_usernames_directories = use_instagram_scraper(LIST_OF_USERNAME_DIRECTORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_files, aug_files = get_files(list_of_usernames_directories,\n",
    "                                   with_augment=True,\n",
    "                                   aug_file_path=AUG_FILE_DIR\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 70% of images to training data, 20% of images to test data, and 10% of images to holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success_clean = move_files(clean_files,\n",
    "                           [0.7,0.2,0.1],\n",
    "                           CLEAN_DATA_DIR)\n",
    "\n",
    "success_aug = move_files(aug_files,\n",
    "                         [0.7,0.2,0.1],\n",
    "                         AUG_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn images into an image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generators = get_generators(rescale=False, \n",
    "                            image_gen=None, \n",
    "                            train_dir=TRAIN_DIR, \n",
    "                            test_dir=TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(224,224,3))\n",
    "fit_model = train_model(model,\n",
    "                        nb_epoch=15,\n",
    "                        generators=generators,\n",
    "                        model_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split model into top layer and other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot, top = split_model(model=keras.models.load_model('data/model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info(\"BEFORE GET_FRAMES: \")\n",
    "logger.info(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snap = get_frames(VID_PATH,\n",
    "                  top_layer=top,\n",
    "                  bottom_layers=bot,\n",
    "                  path=GOOD_PATH,\n",
    "                  sim_threshold=SIM_THRESHOLD,\n",
    "                  good_threshold=GOOD_THRESHOLD,\n",
    "                  consecutive=CONSECUTIVE)\n",
    "logger.info(\"AFTER GET_FRAMES: \")\n",
    "logger.info(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snap = show_images_from_folder(GOOD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in snap:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_snap = get_bad_frames(VID_PATH,\n",
    "                  top_layer=top,\n",
    "                  bottom_layers=bot,\n",
    "                  path=BAD_PATH,\n",
    "                  sim_threshold=SIM_THRESHOLD,\n",
    "                  bad_threshold=BAD_THRESHOLD,\n",
    "                  consecutive=CONSECUTIVE)\n",
    "logger.info(\"AFTER GET_FRAMES: \")\n",
    "logger.info(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_snap = show_images_from_folder(BAD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in bad_snap:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
