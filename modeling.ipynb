{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "('BACKEND: ', u'tensorflow')\n"
     ]
    }
   ],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions, preprocess_input\n",
    "from keras.applications import InceptionV3, ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#### SKLEARN IMPORTS ####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import re\n",
    "import skvideo.io\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "% pylab inline\n",
    "% matplotlib inline\n",
    "\n",
    "print(\"BACKEND: \", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "#     plt.imshow(resized)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "#     plt.imshow(rotated_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "    \n",
    "#     plt.imshow(cropped_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image_path, repeat=5):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "    img_paths = []\n",
    "    \n",
    "    for i in range(repeat):\n",
    "        new_dim = int(img_arr.shape[1] * np.random.uniform(low=0.1, high=0.3))\n",
    "        new_img_arr = resize_img(img_arr, new_dim)\n",
    "    #     print(\"RESIZE: \", new_img_arr)\n",
    "\n",
    "        deg = np.random.randint(15, 345)\n",
    "        scale = np.random.uniform(low=1, high=4)\n",
    "        new_img_arr = rotate_img(new_img_arr, deg, scale)\n",
    "    #     print(\"ROTATE: \", new_img_arr)\n",
    "\n",
    "        lower_height = np.random.randint(25, new_img_arr.shape[0])\n",
    "        lower_width = np.random.randint(25, new_img_arr.shape[1])\n",
    "        upper_height = np.random.randint(lower_height, 10000)\n",
    "        upper_width = np.random.randint(lower_width, 10000)\n",
    "\n",
    "        new_img_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "    #     print(\"CROP: \", new_img_arr)\n",
    "\n",
    "        new_img_path = 'data/aug_images/' + 'aug_' + str(i) + \"_\" + re.sub(r\"data/[a-zA-Z]*/\", '', image_path)\n",
    "\n",
    "        new_img = cv2.imwrite(new_img_path, new_img_arr)\n",
    "        img_paths.append(new_img_path)\n",
    "        if not new_img:\n",
    "            print(\"Check image path: \", new_img_path)\n",
    "            img_paths.append('')\n",
    "    \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_aug_arrays(tot_count, files):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - produces a list of numpy arrays for each image in the files list.\n",
    "    INPUT: \n",
    "        - tot_count is the number of files to traverse through.\n",
    "        - files is the list of image files.\n",
    "    OUTPUT:\n",
    "        - X is the list of numpy arrays for the clean images.\n",
    "        - X_aug is the list of numpy arrays for the augmented images.\n",
    "    '''\n",
    "    X = []\n",
    "    X_aug = []\n",
    "    \n",
    "    if tot_count > len(files):\n",
    "        print(\"tot_count exceeds the number of files.\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(tot_count):\n",
    "        # Convert the clean image\n",
    "        clean_img = image.load_img(files[i], target_size=(224,224))\n",
    "        clean_img = image.img_to_array(clean_img)\n",
    "        if clean_img == None:\n",
    "            continue\n",
    "        X.append(clean_img)\n",
    "\n",
    "        # Augment then convert the new image\n",
    "        temp_imgs = augment(files[i])\n",
    "        for temp_img in temp_imgs:\n",
    "            if temp_img == '':\n",
    "                continue\n",
    "            else:\n",
    "                prep_img = image.load_img(temp_img, target_size=(224,224))\n",
    "                prep_img = image.img_to_array(prep_img)\n",
    "                if prep_img == None:\n",
    "                    continue\n",
    "            X_aug.append(prep_img)\n",
    "\n",
    "    if len(X) == len(X_aug):\n",
    "        print(\"Augmenting worked correctly.\")\n",
    "        \n",
    "    X = np.array(X)\n",
    "    X = preprocess_input(X)\n",
    "    \n",
    "    X_aug = np.array(X_aug)\n",
    "    X_aug = preprocess_input(X_aug)\n",
    "        \n",
    "    return X, X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_train_pred, y_test_pred, y_train, y_test):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Get the various classification metrics for the training and test data.\n",
    "    INPUT:\n",
    "        - fit_model must be a pretrained model. \n",
    "        - y_train_pred and y_test_pred must be one dimensional numpy arrays if binary classifier.\n",
    "        - y_train and y_test must be one dimensional numpy arrays if binary classifier.\n",
    "    OUTPUT:\n",
    "        - prints the scores.\n",
    "    '''\n",
    "    true_pred_train = []\n",
    "    true_pred_test = []\n",
    "    \n",
    "    for pred1 in y_train_pred:\n",
    "        if pred1[0] > 0.5:\n",
    "            true_pred_train.append(1)\n",
    "        else:\n",
    "            true_pred_train.append(0)\n",
    "    \n",
    "    for pred2 in y_test_pred:\n",
    "        if pred2[0] > 0.5:\n",
    "            true_pred_test.append(1)\n",
    "        else:\n",
    "            true_pred_test.append(0)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, true_pred_train)\n",
    "    acc_test = accuracy_score(y_test, true_pred_test)\n",
    "    \n",
    "    print(\"ACC TRAIN: \", acc_train)\n",
    "    print(\"ACC TEST: \", acc_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    pre_train = precision_score(y_train, true_pred_train)\n",
    "    pre_test = precision_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"PRE TRAIN: \", pre_train)\n",
    "    print(\"PRE TEST: \", pre_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    rec_train = recall_score(y_train, true_pred_train)\n",
    "    rec_test = recall_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"REC TRAIN: \", rec_train)\n",
    "    print(\"REC TEST: \", rec_test)\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    f1_train = f1_score(y_train, true_pred_train)\n",
    "    f1_test = f1_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"F1 TRAIN: \", f1_train)\n",
    "    print(\"F1 TEST: \", f1_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames(file_path, model):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Given a video file, this function predicts frame-by-frame if the picture is \"good\" or \"bad\".\n",
    "    INPUT:\n",
    "        - file_path is a valid video file. Must be a string.\n",
    "        - model should be fit and able to be predicted on. Ideally should be a binary classifier for this use case.\n",
    "    OUTPUT:\n",
    "        - prints if the frame is good or bad.\n",
    "    '''\n",
    "    # Grab the input device, in this case the webcam\n",
    "    # You can also give path to the video file\n",
    "    vid = skvideo.io.VideoCapture(file_path)\n",
    "    pred_arr = []\n",
    "\n",
    "    try:\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = vid.read()\n",
    "            if not ret:\n",
    "                # Release the Video Device if ret is false\n",
    "                vid.release()\n",
    "                # Message to be displayed after releasing the device\n",
    "                print(\"Released Video Resource\")\n",
    "                break\n",
    "\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            resized = cv2.resize(frame, (224, 224)).astype(np.float32)\n",
    "            pred_arr.append(resized)\n",
    "            if len(pred_arr) > 2:\n",
    "                pred_arr = np.array(pred_arr)\n",
    "                pred = model.predict(pred_arr)\n",
    "                for p in pred:\n",
    "                    if p > 0.5:\n",
    "                        print(\"GOOD PIC\")\n",
    "                    else: \n",
    "                        print(\"BAD PIC\")\n",
    "                pred_arr = []\n",
    "\n",
    "                \n",
    "            axis('off')\n",
    "            imshow(frame)\n",
    "            show()\n",
    "            \n",
    "            # Display the frame until new frame is available\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # Release the Video Device\n",
    "        vid.release()\n",
    "        # Message to be displayed after releasing the device\n",
    "        print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get a list of filenames corresponding to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ny = ['data/humansofny/' + f for f in listdir('data/humansofny/') if isfile(join('data/humansofny/', f))]\n",
    "am = ['data/humansofamsterdam/' + f for f in listdir('data/humansofamsterdam/') if isfile(join('data/humansofamsterdam/', f))]\n",
    "bo = ['data/humansofbombay/' + f for f in listdir('data/humansofbombay/') if isfile(join('data/humansofbombay/', f))]\n",
    "nt = ['data/humansofnewtown/' + f for f in listdir('data/humansofnewtown/') if isfile(join('data/humansofnewtown/', f))]\n",
    "pd = ['data/humansofpdx/' + f for f in listdir('data/humansofpdx/') if isfile(join('data/humansofpdx/', f))]\n",
    "se = ['data/humansofseoul/' + f for f in listdir('data/humansofseoul/') if isfile(join('data/humansofseoul/', f))]\n",
    "\n",
    "# files = ny + am + bo + nt + pd + se\n",
    "files = am\n",
    "clean_files = [loc for loc in am if '.mp4' not in loc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn each image into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create \"bad\" images by resizing, rotating, and cropping the \"good\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot_count = int(len(clean_files) * 1)\n",
    "X, X_aug = get_clean_aug_arrays(tot_count, clean_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(X, 'data/X.pkl')\n",
    "joblib.dump(X_aug, 'data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = joblib.load('data/X.pkl')\n",
    "X_aug = joblib.load('data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the photos \n",
    "* 1 -> original images\n",
    "* 0 -> augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [1 for _ in range(len(X))]\n",
    "y_aug = [0 for _ in range(len(X_aug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tot = np.append(X, X_aug, axis=0)\n",
    "y_tot = np.append(y, y_aug, axis=0).reshape((-1,1))\n",
    "# y_tot = keras.utils.np_utils.to_categorical(y_tot, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tot, y_tot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((3470, 224, 224, 3))\n",
    "X_test = X_test.reshape((868, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "# model = ResNet50(include_top=False, weights='imagenet')\n",
    "# model = InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "last = model.output\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(last)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1)(x)\n",
    "preds = Activation(activation='sigmoid')(x)\n",
    "\n",
    "final_model = Model(input=model.input, output=preds)\n",
    "\n",
    "final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.fit(X_train, y_train, batch_size=100, nb_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = final_model.evaluate(X_test, y_test, batch_size=100)\n",
    "print(\"TEST SCORE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = final_model.predict(X_train)\n",
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ACC TRAIN: ', 0.99855907780979825)\n",
      "('ACC TEST: ', 1.0)\n",
      "\n",
      "\n",
      "('PRE TRAIN: ', 0.99652777777777779)\n",
      "('PRE TEST: ', 1.0)\n",
      "\n",
      "\n",
      "('REC TRAIN: ', 0.99480069324090126)\n",
      "('REC TEST: ', 1.0)\n",
      "\n",
      "\n",
      "('F1 TRAIN: ', 0.99566348655680847)\n",
      "('F1 TEST: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "get_metrics(y_pred_train, y_pred_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save('data/final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights('data/final_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = keras.models.load_model('data/final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOD PIC\n",
      "GOOD PIC\n",
      "GOOD PIC\n",
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "get_frames(\"data/humansofamsterdam/10461265_241148806083097_1125690800_n.mp4\", final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
