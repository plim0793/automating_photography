{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BACKEND: ', u'tensorflow')\n"
     ]
    }
   ],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions, preprocess_input\n",
    "from keras.applications import InceptionV3, ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#### SKLEARN IMPORTS ####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "print(\"BACKEND: \", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path, model='vgg_16'):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Preprocess an image to be in the correct size\n",
    "    INPUT:\n",
    "        - image_path is the location of the image file\n",
    "        - model is the type of pretrained CNN\n",
    "    OUTPUT:\n",
    "        - resized is the resized image\n",
    "    '''\n",
    "    if model == 'vgg_16':\n",
    "        try:\n",
    "            resized = cv2.resize(cv2.imread(image_path), (224, 224)).astype(np.float32)\n",
    "        except:\n",
    "            print(\"Image cannot be resized: \", image_path)\n",
    "            return None\n",
    "\n",
    "        resized[:,:,0] -= 103.939\n",
    "        resized[:,:,1] -= 116.779\n",
    "        resized[:,:,2] -= 123.68\n",
    "        resized = resized.transpose((2,0,1))\n",
    "        resized = np.expand_dims(resized, axis=0)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "#     plt.imshow(resized)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "#     plt.imshow(rotated_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "    \n",
    "#     plt.imshow(cropped_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image_path, repeat=5):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "    img_paths = []\n",
    "    \n",
    "    for i in range(repeat):\n",
    "        new_dim = int(img_arr.shape[1] * np.random.uniform(low=0.1, high=0.3))\n",
    "        new_img_arr = resize_img(img_arr, new_dim)\n",
    "    #     print(\"RESIZE: \", new_img_arr)\n",
    "\n",
    "        deg = np.random.randint(15, 345)\n",
    "        scale = np.random.uniform(low=1, high=4)\n",
    "        new_img_arr = rotate_img(new_img_arr, deg, scale)\n",
    "    #     print(\"ROTATE: \", new_img_arr)\n",
    "\n",
    "        lower_height = np.random.randint(25, new_img_arr.shape[0])\n",
    "        lower_width = np.random.randint(25, new_img_arr.shape[1])\n",
    "        upper_height = np.random.randint(lower_height, 10000)\n",
    "        upper_width = np.random.randint(lower_width, 10000)\n",
    "\n",
    "        new_img_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "    #     print(\"CROP: \", new_img_arr)\n",
    "\n",
    "        new_img_path = 'data/aug_images/' + 'aug_' + str(i) + \"_\" + re.sub(r\"data/[a-zA-Z]*/\", '', image_path)\n",
    "\n",
    "        new_img = cv2.imwrite(new_img_path, new_img_arr)\n",
    "        img_paths.append(new_img_path)\n",
    "        if not new_img:\n",
    "            print(\"Check image path: \", new_img_path)\n",
    "            img_paths.append('')\n",
    "    \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_aug_arrays(tot_count, files):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - produces a list of numpy arrays for each image in the files list.\n",
    "    INPUT: \n",
    "        - tot_count is the number of files to traverse through.\n",
    "        - files is the list of image files.\n",
    "    OUTPUT:\n",
    "        - X is the list of numpy arrays for the clean images.\n",
    "        - X_aug is the list of numpy arrays for the augmented images.\n",
    "    '''\n",
    "    X = []\n",
    "    X_aug = []\n",
    "    \n",
    "    if tot_count > len(files):\n",
    "        print(\"tot_count exceeds the number of files.\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(tot_count):\n",
    "        # Convert the clean image\n",
    "        clean_img = image.load_img(files[i], target_size=(224,224))\n",
    "        clean_img = image.img_to_array(clean_img)\n",
    "        if clean_img == None:\n",
    "            continue\n",
    "        X.append(clean_img)\n",
    "\n",
    "        # Augment then convert the new image\n",
    "        temp_imgs = augment(files[i])\n",
    "        for temp_img in temp_imgs:\n",
    "            if temp_img == '':\n",
    "                continue\n",
    "            else:\n",
    "                prep_img = image.load_img(temp_img, target_size=(224,224))\n",
    "                prep_img = image.img_to_array(prep_img)\n",
    "                if prep_img == None:\n",
    "                    continue\n",
    "            X_aug.append(prep_img)\n",
    "\n",
    "    if len(X) == len(X_aug):\n",
    "        print(\"Augmenting worked correctly.\")\n",
    "        \n",
    "    X = np.array(X)\n",
    "    X = preprocess_input(X)\n",
    "    \n",
    "    X_aug = np.array(X_aug)\n",
    "    X_aug = preprocess_input(X_aug)\n",
    "        \n",
    "    return X, X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(fit_model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Get the various classification metrics for the training and test data.\n",
    "    INPUT:\n",
    "        - fit_model must be a pretrained model. \n",
    "        - X_train and X_test must be numpy arrays in the correct dimensions.\n",
    "        - y_train and y_test must be one dimensional numpy arrays if binary classifier.\n",
    "    OUTPUT:\n",
    "        - prints the scores.\n",
    "    '''\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    true_pred_train = []\n",
    "    true_pred_test = []\n",
    "    \n",
    "    for pred1 in pred_train:\n",
    "        if pred1[0] > 0.5:\n",
    "            true_pred_train.append(1)\n",
    "        else:\n",
    "            true_pred_train.append(0)\n",
    "    \n",
    "    for pred2 in pred_test:\n",
    "        if pred2[0] > 0.5:\n",
    "            true_pred_test.append(1)\n",
    "        else:\n",
    "            true_pred_test.append(0)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, true_pred_train)\n",
    "    acc_test = accuracy_score(y_test, true_pred_test)\n",
    "    \n",
    "    print(\"ACC TRAIN: \", acc_train)\n",
    "    print(\"ACC TEST: \", acc_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    pre_train = precision_score(y_train, true_pred_train)\n",
    "    pre_test = precision_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"PRE TRAIN: \", pre_train)\n",
    "    print(\"PRE TEST: \", pre_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    rec_train = recall_score(y_train, true_pred_train)\n",
    "    rec_test = recall_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"REC TRAIN: \", rec_train)\n",
    "    print(\"REC TEST: \", rec_test)\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    f1_train = f1_score(y_train, true_pred_train)\n",
    "    f1_test = f1_score(y_test, true_pred_test)\n",
    "\n",
    "    print(\"F1 TRAIN: \", f1_train)\n",
    "    print(\"F1 TEST: \", f1_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get a list of filenames corresponding to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ny = ['data/humansofny/' + f for f in listdir('data/humansofny/') if isfile(join('data/humansofny/', f))]\n",
    "am = ['data/humansofamsterdam/' + f for f in listdir('data/humansofamsterdam/') if isfile(join('data/humansofamsterdam/', f))]\n",
    "bo = ['data/humansofbombay/' + f for f in listdir('data/humansofbombay/') if isfile(join('data/humansofbombay/', f))]\n",
    "nt = ['data/humansofnewtown/' + f for f in listdir('data/humansofnewtown/') if isfile(join('data/humansofnewtown/', f))]\n",
    "pd = ['data/humansofpdx/' + f for f in listdir('data/humansofpdx/') if isfile(join('data/humansofpdx/', f))]\n",
    "se = ['data/humansofseoul/' + f for f in listdir('data/humansofseoul/') if isfile(join('data/humansofseoul/', f))]\n",
    "\n",
    "# files = ny + am + bo + nt + pd + se\n",
    "files = am\n",
    "clean_files = [loc for loc in am if '.mp4' not in loc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn each image into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create \"bad\" images by resizing, rotating, and cropping the \"good\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot_count = int(len(clean_files) * 1)\n",
    "X, X_aug = get_clean_aug_arrays(tot_count, clean_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(X, 'data/X.pkl')\n",
    "joblib.dump(X_aug, 'data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = joblib.load('data/X.pkl')\n",
    "X_aug = joblib.load('data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the photos \n",
    "* 1 -> original images\n",
    "* 0 -> augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [1 for _ in range(len(X))]\n",
    "y_aug = [0 for _ in range(len(X_aug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tot = np.append(X, X_aug, axis=0)\n",
    "y_tot = np.append(y, y_aug, axis=0).reshape((-1,1))\n",
    "# y_tot = keras.utils.np_utils.to_categorical(y_tot, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tot, y_tot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((3470, 224, 224, 3))\n",
    "X_test = X_test.reshape((868, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "# model = ResNet50(include_top=False, weights='imagenet')\n",
    "# model = InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "last = model.output\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(last)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1)(x)\n",
    "preds = Activation(activation='sigmoid')(x)\n",
    "\n",
    "final_model = Model(input=model.input, output=preds)\n",
    "\n",
    "final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0564 - acc: 0.9937   \n",
      "Epoch 2/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0426 - acc: 0.9960   \n",
      "Epoch 3/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0415 - acc: 0.9951   \n",
      "Epoch 4/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0286 - acc: 0.9963   \n",
      "Epoch 5/15\n",
      "3470/3470 [==============================] - 395s - loss: 0.0330 - acc: 0.9957   \n",
      "Epoch 6/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0297 - acc: 0.9974   \n",
      "Epoch 7/15\n",
      "3470/3470 [==============================] - 394s - loss: 0.0186 - acc: 0.9977   \n",
      "Epoch 8/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0199 - acc: 0.9980   \n",
      "Epoch 9/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0239 - acc: 0.9980   \n",
      "Epoch 10/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0263 - acc: 0.9971   \n",
      "Epoch 11/15\n",
      "3470/3470 [==============================] - 392s - loss: 0.0165 - acc: 0.9983   \n",
      "Epoch 12/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0187 - acc: 0.9980   \n",
      "Epoch 13/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0164 - acc: 0.9986   \n",
      "Epoch 14/15\n",
      "3470/3470 [==============================] - 393s - loss: 0.0159 - acc: 0.9974   \n",
      "Epoch 15/15\n",
      "3470/3470 [==============================] - 392s - loss: 0.0217 - acc: 0.9974   \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected input_31 to have shape (None, 224, 224, 3) but got array with shape (868, 3, 224, 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-fdd9ad75cd80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TEST SCORE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/icarus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;31m# prepare inputs, delegate logic to _test_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/icarus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1030\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/icarus/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected input_31 to have shape (None, 224, 224, 3) but got array with shape (868, 3, 224, 224)"
     ]
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train, batch_size=100, nb_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868/868 [==============================] - 102s   \n",
      "('TEST SCORE: ', [0.016284651539159683, 0.99769585473196842])\n"
     ]
    }
   ],
   "source": [
    "score = final_model.evaluate(X_test, y_test, batch_size=100)\n",
    "print(\"TEST SCORE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save('data/final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_train = final_model.predict(X_train)\n",
    "y_pred_test = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-7f2c1a9d4ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-11517a3e6ba8>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(fit_model, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpred1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpred1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mtrue_pred_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "get_metrics(final_model, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
