{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BACKEND: ', u'tensorflow')\n"
     ]
    }
   ],
   "source": [
    "#### KERAS IMPORTS ####\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#### SKLEARN IMPORTS ####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#### OTHER IMPORTS ####\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "print(\"BACKEND: \", keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path, model='vgg_16'):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Preprocess an image to be in the correct size\n",
    "    INPUT:\n",
    "        - image_path is the location of the image file\n",
    "        - model is the type of pretrained CNN\n",
    "    OUTPUT:\n",
    "        - resized is the resized image\n",
    "    '''\n",
    "    if model == 'vgg_16':\n",
    "        try:\n",
    "            resized = cv2.resize(cv2.imread(image_path), (224, 224)).astype(np.float32)\n",
    "        except:\n",
    "            print(\"Image cannot be resized: \", image_path)\n",
    "            return None\n",
    "\n",
    "        resized[:,:,0] -= 103.939\n",
    "        resized[:,:,1] -= 116.779\n",
    "        resized[:,:,2] -= 123.68\n",
    "        resized = resized.transpose((2,0,1))\n",
    "        resized = np.expand_dims(resized, axis=0)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(orig_img, new_dim):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - resizes the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - new_dim is the base number of pixels for the new image.\n",
    "    OUTPUT:\n",
    "        - resized is a numpy array of the resized image.\n",
    "    '''\n",
    "    r = float(new_dim) / orig_img.shape[1]\n",
    "    dim = (new_dim, int(orig_img.shape[0] * r))\n",
    "    resized = cv2.resize(orig_img, dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "#     plt.imshow(resized)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_img(orig_img, deg_rot, scale):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - rotates the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - scale (btwn 0 and 1) zooms in on the image. scale (> 1) zooms out on the image. \n",
    "        - scale can be used to crop the image based only on the center.\n",
    "    OUTPUT:\n",
    "        - rotated_img is a numpy array of the rotated image.\n",
    "    '''\n",
    "    (height, width) = orig_img.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    matrix = cv2.getRotationMatrix2D(center,\n",
    "                                     angle=deg_rot,\n",
    "                                     scale=scale)\n",
    "    rotated_img = cv2.warpAffine(orig_img,\n",
    "                                 matrix,\n",
    "                                 (width, height))\n",
    "#     plt.imshow(rotated_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(orig_img, h1, h2, w1, w2):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - crops the original image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "        - h1 and h2 defines height\n",
    "        - w1 and w2 defines the width\n",
    "    OUTPUT:\n",
    "        - cropped_img is a numpy array of the cropped image.\n",
    "    '''\n",
    "    cropped_img = orig_img[h1:h2, w1:w2]\n",
    "    \n",
    "#     plt.imshow(cropped_img)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image_path):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - randomly augments the image.\n",
    "    INPUT: \n",
    "        - orig_img is a numpy array (use cv2.imread() to transform img into numpy array).\n",
    "    OUTPUT:\n",
    "        - new_img is a numpy array of the augmented image.\n",
    "    '''\n",
    "#     aug_method = np.random.randint(1,4)\n",
    "    \n",
    "    img_arr = cv2.imread(image_path)\n",
    "    \n",
    "#     if aug_method == 1:\n",
    "    new_dim = int(img_arr.shape[1] * np.random.uniform(low=0.1, high=0.3))\n",
    "    new_img_arr = resize_img(img_arr, new_dim)\n",
    "#     print(\"RESIZE: \", new_img_arr)\n",
    "    \n",
    "#     elif aug_method == 2:\n",
    "    deg = np.random.randint(15, 345)\n",
    "    scale = np.random.uniform(low=1, high=4)\n",
    "    new_img_arr = rotate_img(new_img_arr, deg, scale)\n",
    "#     print(\"ROTATE: \", new_img_arr)\n",
    "    \n",
    "#     elif aug_method == 3:\n",
    "    lower_height = np.random.randint(1, new_img_arr.shape[0])\n",
    "    lower_width = np.random.randint(1, new_img_arr.shape[1])\n",
    "    upper_height = np.random.randint(lower_height, 10000)\n",
    "    upper_width = np.random.randint(lower_width, 10000)\n",
    "        \n",
    "    new_img_arr = crop_img(new_img_arr, h1=lower_height, h2=upper_height, w1=lower_width, w2=upper_width)\n",
    "#     print(\"CROP: \", new_img_arr)\n",
    "    \n",
    "    new_img_path = 'data/aug_imagess/' + 'aug_' + re.sub(r\"data/[a-zA-Z]*/\", '', image_path)\n",
    "    \n",
    "    new_img = cv2.imwrite(new_img_path, new_img_arr)\n",
    "    if not new_img:\n",
    "        print(\"Check image path: \", new_img_path)\n",
    "        return [], ''\n",
    "    \n",
    "    return new_img_arr, new_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_aug_arrays(tot_count, files):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - produces a list of numpy arrays for each image in the files list.\n",
    "    INPUT: \n",
    "        - tot_count is the number of files to traverse through.\n",
    "        - files is the list of image files.\n",
    "    OUTPUT:\n",
    "        - X is the list of numpy arrays for the clean images.\n",
    "        - X_aug is the list of numpy arrays for the augmented images.\n",
    "    '''\n",
    "    X = []\n",
    "    X_aug = []\n",
    "    \n",
    "    if tot_count > len(files):\n",
    "        print(\"tot_count exceeds the number of files.\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(tot_count):\n",
    "        # Convert the clean image\n",
    "        clean_img = prepare_image(files[i])\n",
    "        if clean_img == None:\n",
    "            continue\n",
    "        X.append(clean_img.reshape((3, 224, 224)))\n",
    "\n",
    "        # Augment then convert the new image\n",
    "        temp_img_arr, temp_img = augment(files[i])\n",
    "        if temp_img_arr == []:\n",
    "            continue\n",
    "        else:\n",
    "            prep_img = prepare_image(temp_img)\n",
    "            if prep_img == None:\n",
    "                continue\n",
    "        X_aug.append(prep_img.reshape((3, 224, 224)))\n",
    "\n",
    "    if len(X) == len(X_aug):\n",
    "        print(\"Augmenting worked correctly.\")\n",
    "        \n",
    "    X = np.array(X)\n",
    "    X_aug = np.array(X_aug)\n",
    "        \n",
    "    return X, X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net(block1, block2, block3, block4, num_classes, weights_path=None):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Sets the structure of the neural network\n",
    "    INPUT:\n",
    "        - Optional weights. Default to None.\n",
    "        - block1 through block4 are the number of neurons at each block.\n",
    "            - the number of neurons at each conv layer in a single block are assumed to be the same.\n",
    "        - num_classes is the number of classes in the target variable.\n",
    "    OUTPUT:\n",
    "        - Structured model.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    \n",
    "    ## BLOCK 1 ##\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(block1, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block1, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    ## BLOCK 2 ##\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block2, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block2, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block2, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    ## BLOCK 3 ##\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block3, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block3, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(block3, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    ## BLOCK 4 ##\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(block4, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(block4, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(fit_model, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        - Get the various classification metrics for the training and test data.\n",
    "    INPUT:\n",
    "        - fit_model must be a pretrained model. \n",
    "        - X_train and X_test must be numpy arrays in the correct dimensions.\n",
    "        - y_train and y_test must be one dimensional numpy arrays if binary classifier.\n",
    "    OUTPUT:\n",
    "        - prints the scores.\n",
    "    '''\n",
    "    pred_train = model.predict_classes(X_train)\n",
    "    pred_test = model.predict_classes(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    \n",
    "    print(\"ACC TRAIN: \", acc_train)\n",
    "    print(\"ACC TEST: \", acc_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    pre_train = precision_score(y_train, pred_train)\n",
    "    pre_test = precision_score(y_test, pred_test)\n",
    "\n",
    "    print(\"PRE TRAIN: \", pre_train)\n",
    "    print(\"PRE TEST: \", pre_test)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    rec_train = recall_score(y_train, pred_train)\n",
    "    rec_test = recall_score(y_test, pred_test)\n",
    "\n",
    "    print(\"REC TRAIN: \", rec_train)\n",
    "    print(\"REC TEST: \", rec_test)\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    f1_train = f1_score(y_train, pred_train)\n",
    "    f1_test = f1_score(y_test, pred_test)\n",
    "\n",
    "    print(\"F1 TRAIN: \", f1_train)\n",
    "    print(\"F1 TEST: \", f1_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get a list of filenames corresponding to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ny = ['data/humansofny/' + f for f in listdir('data/humansofny/') if isfile(join('data/humansofny/', f))]\n",
    "am = ['data/humansofamsterdam/' + f for f in listdir('data/humansofamsterdam/') if isfile(join('data/humansofamsterdam/', f))]\n",
    "bo = ['data/humansofbombay/' + f for f in listdir('data/humansofbombay/') if isfile(join('data/humansofbombay/', f))]\n",
    "nt = ['data/humansofnewtown/' + f for f in listdir('data/humansofnewtown/') if isfile(join('data/humansofnewtown/', f))]\n",
    "pd = ['data/humansofpdx/' + f for f in listdir('data/humansofpdx/') if isfile(join('data/humansofpdx/', f))]\n",
    "se = ['data/humansofseoul/' + f for f in listdir('data/humansofseoul/') if isfile(join('data/humansofseoul/', f))]\n",
    "\n",
    "files = ny # + am + bo + nt + pd + se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn each image into a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create \"bad\" images by resizing, rotating, and cropping the \"good\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:22: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:32: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting worked correctly.\n"
     ]
    }
   ],
   "source": [
    "tot_count = int(len(files) * 1)\n",
    "X, X_aug = get_clean_aug_arrays(tot_count, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/X_aug.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X, 'data/X.pkl')\n",
    "joblib.dump(X_aug, 'data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = joblib.load('data/X.pkl')\n",
    "X_aug = joblib.load('data/X_aug.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the photos \n",
    "* 1 -> original images\n",
    "* 0 -> augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [1 for _ in range(len(X))]\n",
    "y_aug = [0 for _ in range(len(X_aug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tot = np.append(X, X_aug, axis=0)\n",
    "y_tot = np.append(y, y_aug, axis=0).reshape((-1,1))\n",
    "y_tot = keras.utils.to_categorical(y_tot, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tot, y_tot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = neural_net(block1=16, block2=32, block3=64, block4=128, num_classes=2)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2400/6814 [=========>....................] - ETA: 524s - loss: 0.9589"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=200, epochs=15)\n",
    "score = model.evaluate(X_test, y_test, batch_size=200)\n",
    "print(\"TEST SCORE: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_metrics(model, X_train, X_test, y_train[:,0], y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
